{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96ec6ca-ac2c-4ac5-aabb-7af398f8b277",
   "metadata": {},
   "source": [
    "## The Elephant in the Room\n",
    "Okay, so there are about 50 billion posts about [scikit-learn](https://scikit-learn.org/stable/)(aka `sklearn`) and it's many amazing features, so what's the point of one more? This is a fair question, as many of them are truly excellent (even the internal documentation is brilliant) covering many possible topics. I personally have learned a ton through these posts and hope the amazing content continues. \n",
    "\n",
    "However, I feel like there is a gap that needs to be addressed. While there is so much available information about how to train and fit the latest and greatest algorithm, there is a corresponding lack of what it takes to use these methods \"safely\". [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning) is _ultimately_ based on a strong theoretical framework that deals with the data-generating process (and associated facets of this) and how this can be exploited. The specific algorithms attempt to address some specific aspect of the framework and, in doing so, make several assumptions (e.g. \"you are probably similar to your neighbor\", \"features are independent, given their label\"). But these assumptions aren't always clear and can create some bad situations where the wrong tool is used in the wrong way/situation. What I hope to show in this post (and several others) is a way to use `sklearn` in a robust way, where some best practices can be followed.\n",
    "\n",
    "In particular, these next posts will go through the implementation of [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) and [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV). These approaches are of great benefit in that they help the DS/ML practitioner prevent things like \"[leakage](https://machinelearningmastery.com/data-leakage-machine-learning/)\" or [over/underfitting](https://en.wikipedia.org/wiki/Overfitting). These topics take a while to go through, so this is likely going to be split into a few different posts.\n",
    "\n",
    "**WARNING:** Though these approaches will help any DS/ML practitioner make better products, there is no guarantee that you are using the right algorithm in the correct way, or that you have collected/cleaned your data appropriately. What we do is as much art as it is science, and, like craftspeople from long ago, we should strive to learn as many tools and techniques as thoroughly as we can to ensure we create the best products possible. To that end, as always, I look forward to hearing from people who know more about ways that my own code/understanding could be improved. Never hesitate to reach out to me.\n",
    "\n",
    "So without further ado, onto **Pipelines**!!\n",
    "\n",
    "## Pipelines\n",
    "The Pipeline object is one of the most useful tools within the scikit infrastructure. Though very simple and flexible to employ, they provide a powerful means to automate ML workflows which is especially useful when the models will be fit using **Cross-Validation (CV)** and/or require a number of transformations or preprocessing steps. Prior to this, most ML users would have to write their own custom functions to perform these operations. This was not only time-consuming and exhaustive (particularly when trying to make one function play nicely with subsequent functions) but also risky, as there are a number of places where inadvertent leakage could occur.  \n",
    "\n",
    "A classic example of leakage occurred when using CV in conjunction with **scaling** the data.  Usually data was scaled first, and then CV was applied. This seems perfectly reasonable or even trivial. But doing this \"taught\" each individual observation something about the entire dataset which would then go into the modeling process. For instance, if MinMaxScaling were used, each datapoint is now encoded with information about the size of the largest and smallest observations in the data set, even if those values were being held out of the specific training folds.  \n",
    "  \n",
    "\n",
    "**Pipelines** make it possible to \"do the right thing\" even if you have a number of tasks to accomplish per training fold.  \n",
    "\n",
    "We'll start by making some generic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a9de20-898a-4b4c-86b6-e7210613a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc9e32-2d37-46ee-a685-0a2171dcd41c",
   "metadata": {},
   "source": [
    "### A Regression example\n",
    "\n",
    "We are loading the \"Boston Housing\" dataset in this case (from sklearn).\n",
    "\n",
    "Since the focus is more on the capabilities and less on _actually_ solving this, we won't do much in the way of EDA. In order to show off tuning multiple hyperparameters, we will use a Random Forest Regressor.\n",
    "\n",
    "We start by just importing the dataset and then making testing and training data.  \n",
    "\n",
    "**NOTE:** I'm leaving this call in for the \"Boston Housing\" dataset for now, but I do agree with the maintainers that it's a pretty messed up dataset with over racial issues.  So I'll leave the warning here as a reminder and will later correct this to use either their suggestion or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6930c5-2292-47a2-ba38-dd87d57b4715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Loading the RF Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Importing data; keeping it in this form to enable keeping feature names\n",
    "boston = datasets.load_boston(return_X_y = False)\n",
    "regression_X, regression_y = boston.data, boston.target\n",
    "\n",
    "# Creating Test and Training sets\n",
    "regression_X_train, regression_X_test, regression_y_train, regression_y_test = train_test_split(\n",
    "    regression_X, regression_y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b6740-9055-4291-994a-e8f4e815de82",
   "metadata": {},
   "source": [
    "Now at this stage in the process, we know we will do Cross-Validation to make sure we are reducing overfitting. However, we also have not only model hyperparameters, but maybe a few other aspects we'd like to try. For instance, we may want to find out if scaling the data or performing dimension reduction will help. As discussed above, these operations need to be performed within each step of the Cross-Validation process, and below we will show how this is done within Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22615711-ff62-4662-ab13-55f5549d001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scaler object\n",
    "scaler = StandardScaler()\n",
    "# Creating a PCA object\n",
    "pca = PCA(random_state = 1234)\n",
    "# Initialize the model\n",
    "rf = RandomForestRegressor(random_state = 1234, n_estimators = 50,\n",
    "                          max_features = 'sqrt')\n",
    "\n",
    "# Now we will create an execution plan using Pipelines. This will provide an execution plan during GridSearchCV\n",
    "#\n",
    "# To do so, we create a Pipeline object and we name the steps we call in the order we want them run.  The names used \n",
    "#        are arbitrary.\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "                    ('scaling', scaler),\n",
    "                    ('pca', pca), \n",
    "                    ('random_forest', rf)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57410994-43e8-4856-8040-ad9337c037eb",
   "metadata": {},
   "source": [
    "That's it -- we've just made the pipeline and could move forward.  But you will have noticed that each of the three objects called above have various parameters that could/should be called and weren't. Don't worry! These are the hyperparameters we want to test later, but this happens as part of...\n",
    "\n",
    "## GridSearchCV\n",
    "**GridSearchCV** is the other great feature of scikit; the ability to run Cross-Validation while also tuning hyperparameters. The main worker of GridSearchCV is the _param_grid_ object. With this object, you can reference named objects in the Pipeline object we made earlier, such as the number of Principal Components to use or model-specific hyperparameters.  In fact, there are even more advanced options available but we'll discuss later. But here we will try to find better values for PCA and the RF Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7fb063-b060-4031-baea-0d19a42c826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in some values to explore for PCA and the RF Regressor\n",
    "param_grid = {\n",
    "    'pca__n_components': [4, 9, 13],\n",
    "    'random_forest__max_depth': [3, 4],\n",
    "    'random_forest__min_weight_fraction_leaf': [0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b6a89-9ab0-4216-b98c-60a293b8047d",
   "metadata": {},
   "source": [
    "While this is a fairly simple example, it illustrates the simplicity of creating these objects.  \n",
    "\n",
    "Note that the names we assigned when we make the _Pipeline_ object above are how we specify which object is being tested.  In this way, any parameter belonging to the method can be tested by simply calling the name, '__' and then the method name.\n",
    "\n",
    "e.g. `'random_forest' + '__' + 'min_impurity_split' `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5fe564-25a5-4d13-85fc-b7a064c19009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('scaling', StandardScaler()),\n",
      "                                       ('pca', PCA(random_state=1234)),\n",
      "                                       ('random_forest',\n",
      "                                        RandomForestRegressor(max_features='sqrt',\n",
      "                                                              n_estimators=50,\n",
      "                                                              random_state=1234))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'pca__n_components': [4, 9, 13],\n",
      "                         'random_forest__max_depth': [3, 4],\n",
      "                         'random_forest__min_weight_fraction_leaf': [0.1, 0.2]},\n",
      "             verbose=10)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GridSearchCV object with 5-fold CV\n",
    "# Here Verbose is set to 10 to show more information of the fitting process; by default it is zero\n",
    "regression_cv = GridSearchCV(estimator = pipe, param_grid = param_grid, n_jobs = -1, cv = 5, verbose = 10)\n",
    "\n",
    "# Now let's look at the actual object as part of a sanity check\n",
    "print(regression_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab18d360-c4f8-4f87-80f0-3d6be67d4894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                                       ('pca', PCA(random_state=1234)),\n",
       "                                       ('random_forest',\n",
       "                                        RandomForestRegressor(max_features='sqrt',\n",
       "                                                              n_estimators=50,\n",
       "                                                              random_state=1234))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'pca__n_components': [4, 9, 13],\n",
       "                         'random_forest__max_depth': [3, 4],\n",
       "                         'random_forest__min_weight_fraction_leaf': [0.1, 0.2]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to fit the model\n",
    "#  The output is large but this is only because of the 'verbose' argument earlier;\n",
    "#  setting this value to 0 will suppress nearly everything.\n",
    "regression_cv.fit(regression_X_train, regression_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0fcfe9-20a6-4915-ad95-49b2f03e326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 4, 'random_forest__max_depth': 4, 'random_forest__min_weight_fraction_leaf': 0.1}\n",
      "**************************************************\n",
      "0.5476048369309383\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the best fit is and the error terms:\n",
    "print(regression_cv.best_params_)\n",
    "print('*'*50)\n",
    "print(regression_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc63cfb-0f74-4fc3-8c90-052c1c13a31f",
   "metadata": {},
   "source": [
    "Something very cool (but a bit overwhelming, unfortunately) is the ability to look at the raw CV outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4821760e-101f-4a72-886b-4cb519e82d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.11324077, 0.1072083 , 0.10480456, 0.10521579, 0.10304217,\n",
       "        0.1007061 , 0.10587311, 0.10182614, 0.10239372, 0.10151715,\n",
       "        0.1006484 , 0.0768167 ]),\n",
       " 'std_fit_time': array([0.00258553, 0.00363224, 0.00284345, 0.00645333, 0.00191357,\n",
       "        0.00094417, 0.00289251, 0.00319431, 0.00247705, 0.0020844 ,\n",
       "        0.00325542, 0.01047587]),\n",
       " 'mean_score_time': array([0.01246696, 0.01047864, 0.01032453, 0.01012602, 0.00871487,\n",
       "        0.00881858, 0.00903974, 0.00870447, 0.008955  , 0.00853739,\n",
       "        0.00674996, 0.00418406]),\n",
       " 'std_score_time': array([0.00192632, 0.00062928, 0.00066513, 0.00174225, 0.00054977,\n",
       "        0.00025412, 0.00058565, 0.00031903, 0.00027355, 0.00025611,\n",
       "        0.00134098, 0.00084061]),\n",
       " 'param_pca__n_components': masked_array(data=[4, 4, 4, 4, 9, 9, 9, 9, 13, 13, 13, 13],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_random_forest__max_depth': masked_array(data=[3, 3, 4, 4, 3, 3, 4, 4, 3, 3, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_random_forest__min_weight_fraction_leaf': masked_array(data=[0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,\n",
       "                    0.2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'pca__n_components': 4,\n",
       "   'random_forest__max_depth': 3,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.1},\n",
       "  {'pca__n_components': 4,\n",
       "   'random_forest__max_depth': 3,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.2},\n",
       "  {'pca__n_components': 4,\n",
       "   'random_forest__max_depth': 4,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.1},\n",
       "  {'pca__n_components': 4,\n",
       "   'random_forest__max_depth': 4,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.2},\n",
       "  {'pca__n_components': 9,\n",
       "   'random_forest__max_depth': 3,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.1},\n",
       "  {'pca__n_components': 9,\n",
       "   'random_forest__max_depth': 3,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.2},\n",
       "  {'pca__n_components': 9,\n",
       "   'random_forest__max_depth': 4,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.1},\n",
       "  {'pca__n_components': 9,\n",
       "   'random_forest__max_depth': 4,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.2},\n",
       "  {'pca__n_components': 13,\n",
       "   'random_forest__max_depth': 3,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.1},\n",
       "  {'pca__n_components': 13,\n",
       "   'random_forest__max_depth': 3,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.2},\n",
       "  {'pca__n_components': 13,\n",
       "   'random_forest__max_depth': 4,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.1},\n",
       "  {'pca__n_components': 13,\n",
       "   'random_forest__max_depth': 4,\n",
       "   'random_forest__min_weight_fraction_leaf': 0.2}],\n",
       " 'split0_test_score': array([0.50792294, 0.41221636, 0.52767261, 0.41221636, 0.56474313,\n",
       "        0.43017482, 0.60164697, 0.43017482, 0.43889982, 0.31172442,\n",
       "        0.47111766, 0.31172442]),\n",
       " 'split1_test_score': array([0.56575819, 0.41407164, 0.59760597, 0.41407164, 0.51053226,\n",
       "        0.41281536, 0.55515713, 0.41281536, 0.46004965, 0.29091567,\n",
       "        0.502551  , 0.29091567]),\n",
       " 'split2_test_score': array([0.61798108, 0.49861173, 0.64747259, 0.49861173, 0.57214956,\n",
       "        0.45599968, 0.60938748, 0.45599968, 0.49102703, 0.32778688,\n",
       "        0.5456103 , 0.32778688]),\n",
       " 'split3_test_score': array([0.53428506, 0.39937144, 0.56373726, 0.39937144, 0.48259659,\n",
       "        0.35585843, 0.5244989 , 0.35585843, 0.42217372, 0.30944303,\n",
       "        0.46497958, 0.30944303]),\n",
       " 'split4_test_score': array([0.40262003, 0.26333772, 0.40153575, 0.26333772, 0.41492381,\n",
       "        0.28889934, 0.44295297, 0.28889934, 0.36869954, 0.25899161,\n",
       "        0.39901844, 0.25899161]),\n",
       " 'mean_test_score': array([0.52571346, 0.39752178, 0.54760484, 0.39752178, 0.50898907,\n",
       "        0.38874953, 0.54672869, 0.38874953, 0.43616995, 0.29977232,\n",
       "        0.4766554 , 0.29977232]),\n",
       " 'std_test_score': array([0.07163639, 0.07578627, 0.08302699, 0.07578627, 0.05769745,\n",
       "        0.05978242, 0.06045948, 0.05978242, 0.04082926, 0.02350616,\n",
       "        0.04820757, 0.02350616]),\n",
       " 'rank_test_score': array([ 3,  7,  1,  7,  4,  9,  2,  9,  6, 11,  5, 11], dtype=int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is also useful, but prints out a lot of information so it can be hard to interpret.\n",
    "regression_cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af7f6b-1e3a-46e1-bea5-fdd25c884382",
   "metadata": {},
   "source": [
    "Now at this point, we have created a lot of great information that we can use moving forward. But realistically, we just want to take the _best_ model learned through our CV and put that forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbb0238-192d-4923-b831-cbafeb9a625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.986013716574084\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = regression_cv.best_estimator_\n",
    "boston_predictions = rf_regressor.predict(regression_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Printing the RMSE for fun....\n",
    "print(mean_squared_error(regression_y_test, boston_predictions, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1baca-1764-463c-a40f-4fccb3d969d4",
   "metadata": {},
   "source": [
    "Now at this point we would usually do a lot more to check out the tuning, fitting, etc...,.  However, this is out of the scope of this post, and we'll focus more on this in later posts.  But for now, we are only attempting to show off Pipelines and GridSearchCV. :) However, I did allude to some additional features that could be included and we'll do a Classification example to illustrate these.\n",
    "\n",
    "### Classification Example\n",
    "Again we'll use one of the built-in datasets from sklearn, but we'll expand our pipeline usage now. This dataset consists of several features we can hopefully use to correctly determine which class the wine comes from.  \n",
    "\n",
    "To begin with, we load the data as we had before and create some test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b763a0ab-4484-4ca9-8269-978e7f244568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "wine = datasets.load_wine(return_X_y = False)\n",
    "classification_X, classification_y = wine.data, wine.target\n",
    "\n",
    "# Creating Test and Training sets\n",
    "classification_X_train, classification_X_test, classification_y_train, classification_y_test = train_test_split(\n",
    "    classification_X, classification_y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38513c4-a27d-4940-afc4-a88fda4d5cfd",
   "metadata": {},
   "source": [
    "Now this is where things start to get different! The pipeline object we created ensures that the same operations are followed in the same order, and that's it. In our earlier example, we initialized objects for standardization and reductions and _then_ inserted them into our Pipeline object. What's the problem with that? No matter what happens, we _had to_ perform the standardization AND do feature reduction, _even if that made our model performance suffer_!  There is good news though!  \n",
    "\n",
    "With pipelines, we can actually initialize the `Pipeline` object with very little in it, and _then_ have parameters tested within the `param_grid`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d95717-dea2-4d8c-9ada-8e943f6ac511",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('standardization', None),\n",
    "                              ('reduction', None),\n",
    "                              ('classifier', GradientBoostingClassifier(n_estimators = 50, \n",
    "                                                                        max_features = 'sqrt', \n",
    "                                                                        random_state = 1234))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233bf3c0-df96-4fa8-acaa-6fac1c97111b",
   "metadata": {},
   "source": [
    "As you can see, we have created steps for `standardization` and `reduction` but there is actually nothing to be executed. This is actually okay, as we just created the names of steps that can be tested within the parameter grid execution. In order to do that, we make two lists that we can insert into a parameter grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50fa1f6b-c571-4b67-9ff6-ccc0170b3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, PCA(n_components=1, random_state=1234), PCA(n_components=6, random_state=1234), PCA(n_components=11, random_state=1234)]\n"
     ]
    }
   ],
   "source": [
    "## Let's test whether to leave the data as is, or do the standard zero mean unit variance transform\n",
    "standardizations = [None, StandardScaler()]\n",
    "\n",
    "## We can also either leave the data as is, or run PCA with some other number of dimensions.\n",
    "reductions = [None]\n",
    "reductions.extend([PCA(x, random_state = 1234) for x in range(1, classification_X_train.shape[1] + 1, 5)] )\n",
    "\n",
    "#So what does the reductions step actually look like:\n",
    "print(reductions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9063cd0-0777-45d4-92ad-37f9811413f8",
   "metadata": {},
   "source": [
    "Lastly, we insert these objects into the `param_grid` object, and that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb2d011-b5b6-4f0a-a035-914b84d4320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## And wrap up all of these per stage options into a single data structure\n",
    "param_grid = {\n",
    "    'standardization': standardizations,\n",
    "    'reduction': reductions,\n",
    "    'classifier__max_depth': [1,3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba791d4-3e7b-47e0-adeb-c2e5f141be51",
   "metadata": {},
   "source": [
    "Now we insert these into the `GridSearchCV` object we did before, but we added some additional features here as well. \n",
    "\n",
    "Last time, we didn't specify how we wanted the models to be scored. In this case, we can call out that we want the scorer to be determined based on the model that maximizes the [`f1_weighted` score](https://stats.stackexchange.com/questions/283961/where-does-sklearns-weighted-f1-score-come-from#:~:text=The%20F1%20Scores%20are%20calculated,not%20between%20precision%20and%20recall.&text=Its%20intended%20to%20be%20used,some%20samples%20w.r.t.%20the%20others.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644b3229-bff0-47e8-abfd-2252b7ee9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GridSearchCV object with 5-fold CV and `f1_weighted` scoring.\n",
    "classification_cv = GridSearchCV(estimator = pipe, param_grid = param_grid , n_jobs = -1, \n",
    "                                 cv = 5, verbose = 0, scoring = 'f1_weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d236f8b-1a53-4ffe-9aab-3b96139f9bff",
   "metadata": {},
   "source": [
    "Now we just do what we did last time in the Regression example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114bc47c-8155-4879-b1bb-cb061e5df4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardization', None),\n",
       "                                       ('reduction', None),\n",
       "                                       ('classifier',\n",
       "                                        GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                                   n_estimators=50,\n",
       "                                                                   random_state=1234))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__max_depth': [1, 3, 5],\n",
       "                         'reduction': [None,\n",
       "                                       PCA(n_components=1, random_state=1234),\n",
       "                                       PCA(n_components=6, random_state=1234),\n",
       "                                       PCA(n_components=11, random_state=1234)],\n",
       "                         'standardization': [None, StandardScaler()]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to fit the model\n",
    "classification_cv.fit(classification_X_train, classification_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d204b8-1006-4f11-ad7e-72918baf83f9",
   "metadata": {},
   "source": [
    "and check out how well we did..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb8e77f-31a7-49a4-9783-f8bb16b2402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_depth': 3, 'reduction': None, 'standardization': None}\n",
      "**************************************************\n",
      "0.9860006071394075\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the best fit is and the error terms:\n",
    "print(classification_cv.best_params_)\n",
    "print('*'*50)\n",
    "print(classification_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d8247-5eee-4146-a9b3-dda94f7a4918",
   "metadata": {},
   "source": [
    "This is fascinating! This showed us that (at least in this case) the optimal model did not require any reductions or standardizations! We can now take the best estimator as we did last time and make predictions and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023564cc-8ac3-4848-be89-1ae27d3c1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the model using the best estimator...\n",
    "gb_classifier = classification_cv.best_estimator_\n",
    "\n",
    "# ...and make some predictions!\n",
    "wine_predictions = gb_classifier.predict(classification_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf01b8-6683-4f64-8b98-72099001b001",
   "metadata": {},
   "source": [
    "And to get closure, we can check our results, including against our scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eb55d34-a6ac-49a1-96a0-b0f1b16c1a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "0.9454861111111111\n"
     ]
    }
   ],
   "source": [
    "# And for fun, we can check our accuracy and f1-score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Printing the accuracy....\n",
    "print(accuracy_score(classification_y_test, wine_predictions))\n",
    "# ...and the f1-score\n",
    "print(f1_score(classification_y_test, wine_predictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589857e-f594-4fe7-a2a2-05bae480baea",
   "metadata": {},
   "source": [
    "## Summary\n",
    "That's it!  `Pipelines` and `GridSearchCV` gives us the ability to execute the same tasks in the same way while prohibiting snooping and other issues.  Additionally, these methods provide enough flexibility to enable us to even evaluate whether all our steps are helping the model performance.\n",
    "\n",
    "However, there are some obvious areas for improvement that we will touch on in future posts. This will include spicing up our performance by using better CV approaches than `GridSearch`, which is computationally very intensive as your hyperparameter counts increase, as well as more advanced `Pipeline` operations as well as some other topics.  But for now, the next blog post will focus on what we should do _once we have a model we like_: **model evaluation**.\n",
    "\n",
    "The next step in the modeling process, __model evaluation__, is going to be addressed in a future series. \n",
    "\n",
    "Thank you for making it to the end, and if you have any feedback, I'd love to hear it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
